#!/bin/bash
#PBS -P p00
#PBS -q normal
#PBS -l walltime=9:00:00
#PBS -l mem=32GB
#PBS -l ncpus=8
#PBS -l storage=scratch/INSERT_YOUR_PROJECT_CODE_HERE
#PBS -N evolutionary_kan
#PBS -j oe
#PBS -o evolutionary_kan_${PBS_JOBID}.log
#PBS -M INSERT_YOUR_EMAIL_HERE
#PBS -m abe

# PBS Job Script for Running Evolutionary KAN on Gadi
# Walltime: 9 hours as requested
# Resources: 8 CPUs, 32GB RAM (adjust as needed)

echo "=========================================="
echo "Evolutionary KAN - PBS Job"
echo "=========================================="
echo "Job ID: ${PBS_JOBID}"
echo "Job Name: ${PBS_JOBNAME}"
echo "Queue: ${PBS_QUEUE}"
echo "Nodes: $(cat ${PBS_NODEFILE} | sort -u)"
echo "CPUs: ${PBS_NCPUS}"
echo "Start time: $(date)"
echo "=========================================="

# Change to project directory
PROJECT_DIR="${HOME}/KAN_Repo"
cd "${PROJECT_DIR}"

# Load Python module
module load python3/3.10.4

# Activate virtual environment
VENV_DIR="${PROJECT_DIR}/.venv"
source "${VENV_DIR}/bin/activate"

# Set Python path
export PYTHONPATH="${PROJECT_DIR}:${PYTHONPATH}"

# Print environment info
echo ""
echo "Environment Information:"
echo "  Python: $(which python3)"
echo "  PyTorch: $(python3 -c 'import torch; print(torch.__version__)')"
echo "  Working directory: $(pwd)"
echo ""

# Run the evolutionary search
echo "=========================================="
echo "Starting Evolutionary KAN Search"
echo "=========================================="

python3 << 'EOF'
import sys
import os
import torch
import torch.nn as nn
import numpy as np
import time
from pathlib import Path

# Setup paths
sys.path.insert(0, os.path.expanduser('~/KAN_Repo'))
sys.path.insert(0, os.path.expanduser('~/KAN_Repo/section2_new/evolution'))

print("Importing modules...")
from evolutionary_search import EvolutionaryKANSearch

print("\n" + "="*70)
print("EVOLUTIONARY KAN ARCHITECTURE SEARCH ON GADI")
print("="*70)

# Generate synthetic benchmark data
print("\nGenerating benchmark data...")
torch.manual_seed(42)
np.random.seed(42)

# Larger dataset for serious evolution
n_train = 500
n_val = 150
n_test = 100

X_train = torch.randn(n_train, 5)
y_train = (3.0 * X_train[:, 0] +
           2.0 * torch.sin(X_train[:, 1]) +
           X_train[:, 2]**2 +
           0.5 * X_train[:, 3] +
           0.1 * torch.randn(n_train)).reshape(-1, 1)

X_val = torch.randn(n_val, 5)
y_val = (3.0 * X_val[:, 0] +
         2.0 * torch.sin(X_val[:, 1]) +
         X_val[:, 2]**2 +
         0.5 * X_val[:, 3] +
         0.1 * torch.randn(n_val)).reshape(-1, 1)

X_test = torch.randn(n_test, 5)
y_test = (3.0 * X_test[:, 0] +
          2.0 * torch.sin(X_test[:, 1]) +
          X_test[:, 2]**2 +
          0.5 * X_test[:, 3] +
          0.1 * torch.randn(n_test)).reshape(-1, 1)

print(f"  Training samples: {n_train}")
print(f"  Validation samples: {n_val}")
print(f"  Test samples: {n_test}")
print(f"  Input features: {X_train.shape[1]}")

# Configure evolutionary search
print("\nConfiguring evolutionary search...")
evolver = EvolutionaryKANSearch(
    input_dim=5,
    output_dim=1,
    population_size=30,        # Larger population for better exploration
    n_generations=50,          # More generations for convergence
    selection_method='tournament',
    tournament_size=3,
    crossover_rate=0.8,
    mutation_rate=0.3,
    n_elite=3,                 # Preserve top 3
    max_epochs_per_eval=200,   # More training per genome
    objective_weights=(1.0, 0.001, 0.05),  # Accuracy, complexity, speed
    device='cpu',              # CPU on Gadi
    verbose=True
)

# Run evolution
print("\n" + "="*70)
print("Starting Evolution (this will take several hours)...")
print("="*70)

start_time = time.time()
best_genome, history = evolver.evolve(X_train, y_train, X_val, y_val)
evolution_time = time.time() - start_time

print(f"\n{'='*70}")
print("EVOLUTION COMPLETE")
print(f"{'='*70}")
print(f"Total time: {evolution_time/3600:.2f} hours")

# Save results
results_dir = Path(os.path.expanduser('~/KAN_Repo/section2_new/results'))
results_dir.mkdir(parents=True, exist_ok=True)

# Save best genome
import pickle
genome_file = results_dir / f'best_genome_{int(time.time())}.pkl'
with open(genome_file, 'wb') as f:
    pickle.dump(best_genome, f)
print(f"\nBest genome saved to: {genome_file}")

# Save history
history_file = results_dir / f'evolution_history_{int(time.time())}.pkl'
with open(history_file, 'wb') as f:
    pickle.dump(history, f)
print(f"Evolution history saved to: {history_file}")

# Test best model
print(f"\n{'='*70}")
print("Testing Best Model")
print(f"{'='*70}")

best_model = best_genome.to_model()
best_model.eval()

with torch.no_grad():
    y_pred_train = best_model(X_train)
    y_pred_val = best_model(X_val)
    y_pred_test = best_model(X_test)

    train_mse = nn.MSELoss()(y_pred_train, y_train).item()
    val_mse = nn.MSELoss()(y_pred_val, y_val).item()
    test_mse = nn.MSELoss()(y_pred_test, y_test).item()

print(f"\nBest Genome Architecture:")
print(f"  Layers: {best_genome.layer_sizes}")
print(f"  Basis: {best_genome.basis_type}")
print(f"  Grid size: {best_genome.grid_size}")
print(f"  Learning rate: {best_genome.learning_rate:.4f}")
print(f"\nPerformance:")
print(f"  Training MSE: {train_mse:.6f}")
print(f"  Validation MSE: {val_mse:.6f}")
print(f"  Test MSE: {test_mse:.6f}")

# Pareto frontier analysis
print(f"\n{'='*70}")
print("Pareto Frontier Analysis")
print(f"{'='*70}")

pareto_solutions = evolver.get_pareto_frontier()
print(f"\nFound {len(pareto_solutions)} Pareto-optimal solutions:")

for i, sol in enumerate(pareto_solutions[:10]):  # Show top 10
    acc, comp, speed = sol.objectives
    print(f"\n  Solution {i+1}:")
    print(f"    Accuracy score: {acc:.6f}")
    print(f"    Complexity score: {comp:.1f}")
    print(f"    Speed score: {speed:.3f}")
    print(f"    Architecture: {sol.genome.layer_sizes}")

# Save Pareto frontier
pareto_file = results_dir / f'pareto_frontier_{int(time.time())}.pkl'
with open(pareto_file, 'wb') as f:
    pickle.dump(pareto_solutions, f)
print(f"\nPareto frontier saved to: {pareto_file}")

# Evolution statistics
print(f"\n{'='*70}")
print("Evolution Statistics")
print(f"{'='*70}")

cache_stats = evolver.evaluator.get_cache_stats()
print(f"\nFitness Evaluation:")
print(f"  Total evaluations: {cache_stats['total_evaluations']}")
print(f"  Cache hits: {cache_stats['cache_hits']}")
print(f"  Hit rate: {cache_stats['hit_rate']:.1%}")

print(f"\nConvergence:")
print(f"  Initial best fitness: {history['best_fitness'][0]:.6f}")
print(f"  Final best fitness: {history['best_fitness'][-1]:.6f}")
print(f"  Improvement: {history['best_fitness'][-1] - history['best_fitness'][0]:.6f}")

print(f"\nDiversity:")
print(f"  Initial diversity: {history['diversity'][0]:.4f}")
print(f"  Final diversity: {history['diversity'][-1]:.4f}")

print(f"\n{'='*70}")
print("JOB COMPLETE - All results saved")
print(f"{'='*70}")
print(f"Results directory: {results_dir}")

EOF

# Job completion
EXIT_CODE=$?

echo ""
echo "=========================================="
echo "Job Complete"
echo "=========================================="
echo "Exit code: ${EXIT_CODE}"
echo "End time: $(date)"
echo "=========================================="

exit ${EXIT_CODE}
